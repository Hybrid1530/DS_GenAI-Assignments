{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Theory Questions"
      ],
      "metadata": {
        "id": "2awl31EMHIaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: Compare and contrast NLTK and spaCy in terms of features, ease of use,and performance.**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "  | Criteria        | **NLTK**                                                   | **spaCy**                                                            |\n",
        "| --------------- | ---------------------------------------------------------- | -------------------------------------------------------------------- |\n",
        "| **Purpose**     | For teaching, research, and experimentation                | For production-ready, real-world NLP                                 |\n",
        "| **Features**    | Many tools + large corpora; supports classical NLP methods | Modern pretrained models; efficient pipelines; supports transformers |\n",
        "| **Ease of Use** | More steps, less streamlined                               | Very easy, plug-and-play pipelines                                   |\n",
        "| **Performance** | Slower (Python-based)                                      | Much faster (Cython-optimized)                                       |\n",
        "| **Accuracy**    | Good for rule-based tasks                                  | Higher accuracy for NER, POS, parsing                                |\n",
        "| **Best For**    | Learning NLP concepts                                      | Large-scale, industrial applications                                 |\n",
        "                  "
      ],
      "metadata": {
        "id": "3gxXEUfrHLm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: What is TextBlob and how does it simplify common NLP tasks like sentiment analysis and translation?**\n",
        "\n",
        "**Answer:**\n",
        "TextBlob is a simple and beginner-friendly Python library built on top of NLTK and Pattern. It provides an easy API for performing common NLP tasks with minimal code.\n",
        "\n",
        "| Task                   | How TextBlob Helps                                                                                                                                                       |\n",
        "| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
        "| **Sentiment Analysis** | Provides a built-in sentiment method that directly returns **polarity** (positive/negative) and **subjectivity**. No need to train models or preprocess text manually. |\n",
        "| **Translation**        | Offers simple functions like translate() and detect_language() which use underlying translation APIs, making translation a one-line operation.                       |\n",
        "| **Other Tasks**        | Easily performs tokenization, POS tagging, noun phrase extraction, and spelling correction using very short code.                                                        |\n",
        "\n"
      ],
      "metadata": {
        "id": "uPoiKx1AH_7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Explain the role of Standford NLP in academic and industry NLP Projects.**\n",
        "\n",
        "**Answer:**Stanford NLP (also known as Stanford CoreNLP) is a powerful NLP toolkit widely used in both academic research and industry applications because of its accuracy and comprehensive language processing tools.\n",
        "\n",
        "*Role in Academic Projects*\n",
        "* Provides state-of-the-art models for tasks like POS tagging, NER, parsing, sentiment analysis, and coreference resolution.\n",
        "* Widely used for linguistics research, developing new algorithms, and benchmarking NLP models.\n",
        "* Offers a rich, rule-based and statistical approach, making it suitable for experiments and theoretical studies.\n",
        "\n",
        "*Role in Industry Projects*\n",
        "* Used for production-level NLP tasks such as information extraction, customer analytics, document processing, and text understanding.\n",
        "* Known for high accuracy and reliable results, especially in NER and dependency parsing.\n",
        "* Provides server-based APIs, allowing integration into real-time systems in sectors like finance, healthcare, legal, and customer service."
      ],
      "metadata": {
        "id": "KYRENbfyKrQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Describe the architecture and functioning of a Recurrent Natural Network(RNN).**\n",
        "\n",
        "**Answer:**\n",
        "A Recurrent Neural Network (RNN) is a type of neural network designed to process sequential data such as text, speech, or time-series.\n",
        "\n",
        "*Architecture*\n",
        "* Consists of input layer, hidden (recurrent) layer, and output layer.\n",
        "* The hidden layer has recurrent connections, meaning it receives input from the current step and its own previous output.\n",
        "* This creates a loop that allows the network to store information across time steps.\n",
        "\n",
        "*Functioning*\n",
        "* At each time step, the RNN takes an input (e.g., a word or value).\n",
        "* It combines this input with the previous hidden state to generate a new hidden state.\n",
        "* This hidden state acts as the network’s memory, carrying information from earlier steps.\n",
        "* The final output is produced from the hidden state, depending on the task (classification, prediction, etc.)."
      ],
      "metadata": {
        "id": "F03_v1lqLHRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: What is the key difference between LSTM and GRU networks in NLP applications?**\n",
        "\n",
        "**Answer:**\n",
        "| Aspect                | **LSTM (Long Short-Term Memory)**              | **GRU (Gated Recurrent Unit)**          |\n",
        "| --------------------- | ---------------------------------------------- | --------------------------------------- |\n",
        "| **Gates Used**        | Three gates: **input**, **forget**, **output** | Two gates: **reset** and **update**     |\n",
        "| **Memory Components** | Has a **separate cell state** and hidden state | Combines both into **one hidden state** |\n",
        "| **Complexity**        | More complex, more parameters                  | Simpler, fewer parameters               |\n",
        "| **Training Speed**    | Slower                                         | Faster                                  |\n",
        "| **Performance**       | Good for long sequences and complex patterns   | Similar performance but more efficient  |\n",
        "\n"
      ],
      "metadata": {
        "id": "cXAL2mgQLnXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "S182FzhlL320"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 6: Write a Python program using TextBlob to perform sentiment analysis on\n",
        "the following paragraph of text:\n",
        "\n",
        "“I had a great experience using the new mobile banking app. The interface is intuitive,\n",
        "and customer support was quick to resolve my issue. However, the app did crash once\n",
        "during a transaction, which was frustrating\"\n",
        "\n",
        "Your program should print out the polarity and subjectivity scores.\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n",
        "\n",
        "'''\n",
        "from textblob import TextBlob\n",
        "\n",
        "text = \"\"\"I had a great experience using the new mobile banking app.\n",
        "The interface is intuitive, and customer support was quick to resolve my issue.\n",
        "However, the app did crash once during a transaction, which was frustrating.\"\"\"\n",
        "\n",
        "# Create TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# Get sentiment scores\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "# Print results\n",
        "print(\"Polarity:\", polarity)\n",
        "print(\"Subjectivity:\", subjectivity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3TA8CJcL_XZ",
        "outputId": "bfa5128d-4f87-4301-c090-8bf5f4bb91ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.21742424242424244\n",
            "Subjectivity: 0.6511363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 7: Given the sample paragraph below, perform string tokenization and\n",
        "frequency distribution using Python and NLTK:\n",
        "\n",
        "“Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
        "computer science, and artificial intelligence. It enables machines to understand,\n",
        "interpret, and generate human language. Applications of NLP include chatbots,\n",
        "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
        "in modern solutions is becoming increasingly critical.”\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n",
        "'''\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "\n",
        "text = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines\n",
        "linguistics, computer science, and artificial intelligence. It enables machines to\n",
        "understand, interpret, and generate human language. Applications of NLP include\n",
        "chatbots, sentiment analysis, and machine translation. As technology advances,\n",
        "the role of NLP in modern solutions is becoming increasingly critical.\"\"\"\n",
        "\n",
        "# Tokenize text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Frequency Distribution\n",
        "freq = FreqDist(tokens)\n",
        "\n",
        "print(\"Tokens:\")\n",
        "print(tokens)\n",
        "print(\"\\nMost Common Words:\")\n",
        "print(freq.most_common(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYzAkHllMPOg",
        "outputId": "713944e5-9a7d-462b-b252-2534599c74b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'that', 'combines', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'It', 'enables', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'Applications', 'of', 'NLP', 'include', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'As', 'technology', 'advances', ',', 'the', 'role', 'of', 'NLP', 'in', 'modern', 'solutions', 'is', 'becoming', 'increasingly', 'critical', '.']\n",
            "\n",
            "Most Common Words:\n",
            "[(',', 7), ('.', 4), ('NLP', 3), ('and', 3), ('is', 2), ('of', 2), ('Natural', 1), ('Language', 1), ('Processing', 1), ('(', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 8: Implement a basic LSTM model in Keras for a text classification task using\n",
        "the following dummy dataset. Your model should classify sentences as either positive\n",
        "(1) or negative (0).\n",
        "\n",
        "# Dataset\n",
        "texts = [\n",
        "“I love this project”, #Positive\n",
        "“This is an amazing experience”, #Positive\n",
        "“I hate waiting in line”, #Negative\n",
        "“This is the worst service”, #Negative\n",
        "“Absolutely fantastic!” #Positive\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "\n",
        "Preprocess the text, tokenize it, pad sequences, and build an LSTM model to train on\n",
        "this data. You may use Keras with TensorFlow backend.\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Dataset\n",
        "texts = [\n",
        "    \"I love this project\",\n",
        "    \"This is an amazing experience\",\n",
        "    \"I hate waiting in line\",\n",
        "    \"This is the worst service\",\n",
        "    \"Absolutely fantastic!\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "\n",
        "# --------------------------\n",
        "# 1. Text Tokenization\n",
        "# --------------------------\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print(\"Tokenized Sequences:\", sequences)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Padding Sequences\n",
        "# --------------------------\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "print(\"Padded Sequences:\\n\", padded)\n",
        "\n",
        "# Convert labels to array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Build LSTM Model\n",
        "# --------------------------\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=16, input_length=max_len))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --------------------------\n",
        "# 4. Train Model\n",
        "# --------------------------\n",
        "history = model.fit(padded, labels, epochs=10, verbose=1)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Evaluate\n",
        "# --------------------------\n",
        "loss, acc = model.evaluate(padded, labels, verbose=0)\n",
        "print(\"\\nTraining Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knxvAObrM1Ft",
        "outputId": "b6a6d036-d53e-4111-ee35-1e10916ec8db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sequences: [[2, 4, 1, 5], [1, 3, 6, 7, 8], [2, 9, 10, 11, 12], [1, 3, 13, 14, 15], [16, 17]]\n",
            "Padded Sequences:\n",
            " [[ 2  4  1  5  0]\n",
            " [ 1  3  6  7  8]\n",
            " [ 2  9 10 11 12]\n",
            " [ 1  3 13 14 15]\n",
            " [16 17  0  0  0]]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4000 - loss: 0.6943\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4000 - loss: 0.6926\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6000 - loss: 0.6909\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6000 - loss: 0.6891\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6000 - loss: 0.6874\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6000 - loss: 0.6856\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6000 - loss: 0.6837\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6000 - loss: 0.6818\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6000 - loss: 0.6798\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6000 - loss: 0.6777\n",
            "\n",
            "Training Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 9: Using spaCy, build a simple NLP pipeline that includes tokenization,\n",
        "lemmatization, and entity recognition. Use the following paragraph as your dataset:\n",
        "\n",
        "“Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role in the\n",
        "development of India’s atomic energy program. He was the founding director of the Tata\n",
        "Institute of Fundamental Research (TIFR) and was instrumental in establishing the\n",
        "Atomic Energy Commission of India.”\n",
        "\n",
        "Write a Python program that processes this text using spaCy, then prints tokens, their\n",
        "lemmas, and any named entities found.\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n",
        "\n",
        "'''\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role\n",
        "in the development of India’s atomic energy program. He was the founding director\n",
        "of the Tata Institute of Fundamental Research (TIFR) and was instrumental in\n",
        "establishing the Atomic Energy Commission of India.\"\"\"\n",
        "\n",
        "# Process text\n",
        "doc = nlp(text)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Tokenization + Lemmatization\n",
        "# -----------------------------\n",
        "print(\"Tokens and Lemmas:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} --> {token.lemma_}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Named Entity Recognition\n",
        "# -----------------------------\n",
        "print(\"\\nNamed Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} --> {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZoOJzvFNOKa",
        "outputId": "a301946f-0ea4-49b7-9a9f-cc9132e97067"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens and Lemmas:\n",
            "Homi --> Homi\n",
            "Jehangir --> Jehangir\n",
            "Bhaba --> Bhaba\n",
            "was --> be\n",
            "an --> an\n",
            "Indian --> indian\n",
            "nuclear --> nuclear\n",
            "physicist --> physicist\n",
            "who --> who\n",
            "played --> play\n",
            "a --> a\n",
            "key --> key\n",
            "role --> role\n",
            "\n",
            " --> \n",
            "\n",
            "in --> in\n",
            "the --> the\n",
            "development --> development\n",
            "of --> of\n",
            "India --> India\n",
            "’s --> ’s\n",
            "atomic --> atomic\n",
            "energy --> energy\n",
            "program --> program\n",
            ". --> .\n",
            "He --> he\n",
            "was --> be\n",
            "the --> the\n",
            "founding --> found\n",
            "director --> director\n",
            "\n",
            " --> \n",
            "\n",
            "of --> of\n",
            "the --> the\n",
            "Tata --> Tata\n",
            "Institute --> Institute\n",
            "of --> of\n",
            "Fundamental --> Fundamental\n",
            "Research --> Research\n",
            "( --> (\n",
            "TIFR --> TIFR\n",
            ") --> )\n",
            "and --> and\n",
            "was --> be\n",
            "instrumental --> instrumental\n",
            "in --> in\n",
            "\n",
            " --> \n",
            "\n",
            "establishing --> establish\n",
            "the --> the\n",
            "Atomic --> Atomic\n",
            "Energy --> Energy\n",
            "Commission --> Commission\n",
            "of --> of\n",
            "India --> India\n",
            ". --> .\n",
            "\n",
            "Named Entities:\n",
            "Homi Jehangir Bhaba --> FAC\n",
            "Indian --> NORP\n",
            "India --> GPE\n",
            "the Tata Institute of Fundamental Research --> ORG\n",
            "the Atomic Energy Commission of India --> ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: You are working on a chatbot for a mental health platform. Explain how you would leverage LSTM or GRU networks along with libraries like spaCy or Stanford NLP to understand and respond to user input effectively. Detail your architecture, data preprocessing pipeline, and any ethical considerations.**\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "**Answer:**A mental-health chatbot must understand user emotions, context, and intent.To achieve this, we combine spaCy (for preprocessing) with an LSTM/GRU model (for intent/emotion classification).\n",
        "\n",
        "1. Architecture Overview\n",
        "\n",
        "-> Preprocessing Layer (spaCy / Stanford NLP)\n",
        "* Tokenization\n",
        "* Lemmatization\n",
        "* Named Entity Recognition (NER)\n",
        "* Stopword removal\n",
        "* Sentence vectorization\n",
        "\n",
        "-> LSTM/GRU Classification Layer\n",
        "* Takes processed vectors as input\n",
        "* Predicts intent (e.g., stress, sadness, emergency, normal conversation)\n",
        "* Detects sentiment\n",
        "* Routes user to appropriate response module\n",
        "\n",
        "-> Response Generation Layer\n",
        "* Rule-based responses for safety-sensitive cases\n",
        "* Template + retrieval-based responses for normal conversation\n",
        "* No unsafe generative responses in crisis situations\n",
        "\n",
        "2. Ethical Considerations\n",
        "* Privacy: User messages must be encrypted and not stored unnecessarily.\n",
        "* Bias Reduction: Train on balanced, diverse mental-health datasets.\n",
        "* Safety: If the model detects self-harm/suicide intent, escalate to help lines.\n",
        "* Transparency: Inform users that the chatbot is not a therapist.\n"
      ],
      "metadata": {
        "id": "Lj46cTDZNt-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# --------------------------\n",
        "# 1. spaCy preprocessing\n",
        "# --------------------------\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Training dataset\n",
        "texts = [\n",
        "    \"I feel very sad and lonely\",\n",
        "    \"I am extremely anxious today\",\n",
        "    \"I am feeling a bit better now\",\n",
        "    \"I am happy and relaxed\"\n",
        "]\n",
        "\n",
        "labels = [0, 0, 1, 1]  # 0 = distress, 1 = positive\n",
        "\n",
        "# Preprocess training text\n",
        "cleaned = [preprocess(t) for t in texts]\n",
        "\n",
        "# --------------------------\n",
        "# 2. Tokenization + Padding\n",
        "# --------------------------\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(cleaned)\n",
        "seq = tokenizer.texts_to_sequences(cleaned)\n",
        "padded = pad_sequences(seq, padding='post')\n",
        "labels = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Build LSTM Model\n",
        "# --------------------------\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 16),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(padded, labels, epochs=10, verbose=0)\n",
        "\n",
        "# --------------------------\n",
        "# 4. User Input Prediction\n",
        "# --------------------------\n",
        "user_text = input(\"Enter your message: \")\n",
        "\n",
        "clean_user = preprocess(user_text)\n",
        "user_seq = tokenizer.texts_to_sequences([clean_user])\n",
        "user_pad = pad_sequences(user_seq, maxlen=padded.shape[1], padding='post')\n",
        "\n",
        "prediction = model.predict(user_pad)[0][0]\n",
        "\n",
        "if prediction < 0.5:\n",
        "    print(\"Model Output: Distress / Negative Emotion (0)\")\n",
        "else:\n",
        "    print(\"Model Output: Positive Emotion (1)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sh7gjrlOyjh",
        "outputId": "b5b45ebd-2d72-475e-b29b-5632d6d08fe2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your message: i feel sad and  anxious\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Model Output: Distress / Negative Emotion (0)\n"
          ]
        }
      ]
    }
  ]
}