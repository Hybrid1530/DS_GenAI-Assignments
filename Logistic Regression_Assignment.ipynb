{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOD/uhAKpiXwnfTQPq+VPAv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**\n","\n","->Logistic Regression is a statistical and machine learning algorithm used for classification problems, where the dependent variable is categorical.\n","1. Linear Regression is used for predicting continuous numerical values, while Logistic Regression is used for predicting discrete class labels.\n","2.Linear Regression outputs any real number between negative and positive infinity, whereas Logistic Regression outputs probabilities between 0 and 1.\n","3. Linear Regression uses a linear function and Mean Squared Error as its loss function, while Logistic Regression uses a logistic function and Log Loss (Cross-Entropy Loss) for training."],"metadata":{"id":"5bVpHtKsUhbb"}},{"cell_type":"markdown","source":["**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n","\n","->In Logistic Regression, the Sigmoid function plays a crucial role in converting the linear combination of input features which can take any value from negative to positive infinity into a probability value between 0 and 1.\n","This transformation is essential because Logistic Regression predicts the likelihood of an instance belonging to a particular class.\n","\n","\n"],"metadata":{"id":"8-vpKERuUt5w"}},{"cell_type":"markdown","source":["**Question 3: What is Regularization in Logistic Regression and why is it needed?**\n","\n","-> Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function that discourages the model from assigning excessively large weights to features.\n","\n","Overfitting occurs when the model learns noise or irrelevant patterns from the training data, leading to poor performance on new, unseen data. Regularization works by controlling the complexity of the model, effectively simplifying it so that it generalizes better."],"metadata":{"id":"jZ7fBJdLW0na"}},{"cell_type":"markdown","source":["**Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n","\n","->Common evaluation metrics for classification models include: Accuracy, Precision, Recall, F1-score, and the Area Under the ROC Curve (AUC-ROC).\n","\n","1. Accuracy measures the proportion of correctly classified instances out of all instances, but it can be misleading if the data is imbalanced.\n","2. Precision measures the proportion of true positive predictions out of all positive predictions, which is important when the cost of false positives is high.\n","3. Recall (or Sensitivity) measures the proportion of true positives out of all actual positives, which is important when the cost of false negatives is high.\n","4. The F1-score is the harmonic mean of Precision and Recall, providing a balance between them, especially when there is an uneven class distribution.\n","5. The AUC-ROC score measures the model’s ability to distinguish between classes across different classification thresholds, with higher values indicating better performance.\n","\n","These metrics are important because they give a more complete picture of a model’s effectiveness than accuracy alone, helping to choose the right model and tune it based on the specific needs of the problem.\n","\n"],"metadata":{"id":"aSnsSMZlXWKE"}},{"cell_type":"code","source":["\"\"\"\n","Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n","splits into train/test sets, trains a Logistic Regression model,\n","and prints its accuracy. (Use Dataset from sklearn package)\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","data= load_iris()\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","df['target'] = data.target\n","df = df[df['target'] != 2]\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65WiE5PTX5fR","executionInfo":{"status":"ok","timestamp":1754987036409,"user_tz":-330,"elapsed":3876,"user":{"displayName":"Devang Kotkar","userId":"05907746660439424184"}},"outputId":"15cbf0f0-983a-4748-9209-1f78be22b2f1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.00\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge)\n","and print the model coefficients and accuracy. (Use Dataset from sklearn package)\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","data= load_iris()\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","df['target'] = data.target\n","df = df[df['target'] != 2]\n","\n","from sklearn.model_selection import train_test_split\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(penalty='l2', solver='liblinear')\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(\"Model Coefficients:\", model.coef_)\n","print(f\"Accuracy: {accuracy:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2gmK1oFYQ0q","executionInfo":{"status":"ok","timestamp":1754987100287,"user_tz":-330,"elapsed":103,"user":{"displayName":"Devang Kotkar","userId":"05907746660439424184"}},"outputId":"7fd91240-1a60-49bc-e493-5fe80877b545"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Coefficients: [[-0.3753915  -1.39664105  2.15250857  0.96423532]]\n","Accuracy: 1.00\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n","and print the classification report. (Use Dataset from sklearn package)\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","df = pd.DataFrame(iris.data, columns=iris.feature_names)\n","df['target'] = iris.target\n","\n","from sklearn.model_selection import train_test_split\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(multi_class='ovr', solver='liblinear')\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","from sklearn.metrics import classification_report\n","\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfy3DnxwYgTl","executionInfo":{"status":"ok","timestamp":1754987180141,"user_tz":-330,"elapsed":55,"user":{"displayName":"Devang Kotkar","userId":"05907746660439424184"}},"outputId":"b888d2a1-6761-4d67-efc2-72cc126e8dab"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        10\n","           1       1.00      1.00      1.00         9\n","           2       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression\n","and print the best parameters and validation accuracy. (Use Dataset from sklearn package)\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","# Load dataset from sklearn\n","iris = load_iris()\n","df = pd.DataFrame(iris.data, columns=iris.feature_names)\n","df['target'] = iris.target\n","\n","from sklearn.model_selection import train_test_split\n","# Split into features (X) and target (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","from sklearn.linear_model import LogisticRegression\n","# Define the Logistic Regression model\n","model = LogisticRegression(solver='liblinear')\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],\n","    'penalty': ['l1', 'l2']\n","}\n","\n","# Apply GridSearchCV\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, y_train)\n","\n","# Print best parameters and best score\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2rUo6ZhY1X_","executionInfo":{"status":"ok","timestamp":1754987260626,"user_tz":-330,"elapsed":367,"user":{"displayName":"Devang Kotkar","userId":"05907746660439424184"}},"outputId":"6d5e092f-f16b-419e-e260-dd57b7e5a44f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'C': 10, 'penalty': 'l1'}\n","Best Cross-Validation Accuracy: 0.96\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Question 9: Write a Python program to standardize the features before training Logistic Regression\n","and compare the model's accuracy with and without scaling. (Use Dataset from sklearn package)\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import load_iris\n","# Load dataset from sklearn\n","iris = load_iris()\n","df = pd.DataFrame(iris.data, columns=iris.feature_names)\n","df['target'] = iris.target\n","\n","from sklearn.model_selection import train_test_split\n","# Split into features (X) and target (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","from sklearn.linear_model import LogisticRegression\n","\n","# Logistic Regression without scaling\n","model_no_scaling = LogisticRegression(max_iter=200)\n","model_no_scaling.fit(X_train, y_train)\n","y_pred_no_scaling = model_no_scaling.predict(X_test)\n","accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Logistic Regression with scaling\n","model_scaling = LogisticRegression(max_iter=200)\n","model_scaling.fit(X_train_scaled, y_train)\n","y_pred_scaling = model_scaling.predict(X_test_scaled)\n","accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n","\n","# Print results\n","print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n","print(f\"Accuracy with scaling: {accuracy_scaling:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K09qcqz9ZHeo","executionInfo":{"status":"ok","timestamp":1754987331638,"user_tz":-330,"elapsed":656,"user":{"displayName":"Devang Kotkar","userId":"05907746660439424184"}},"outputId":"12414d54-6402-497a-f6f7-c2179ba5025e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy without scaling: 1.00\n","Accuracy with scaling: 1.00\n"]}]},{"cell_type":"markdown","source":["**Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n","\n","-> For this problem, I would follow a structured approach to ensure the Logistic Regression model handles the severe class imbalance and produces reliable predictions.\n","\n"," First, I would start with data understanding and preprocessing by checking for missing values, outliers, and feature distributions. Since Logistic Regression is sensitive to feature scales, I would standardize numerical features using techniques like StandardScaler.\n","\n","For categorical variables, I would apply one-hot encoding. Next, to address the class imbalance (only 5% positive responses), I would try methods such as class weighting (class_weight='balanced' in Logistic Regression), oversampling the minority class with SMOTE, or undersampling the majority class, depending on which works best in cross-validation. During model training, I would perform hyperparameter tuning using GridSearchCV to optimize parameters like C (regularization strength), penalty (L1/L2), and the solver, ensuring I use cross-validation to avoid overfitting. Since this is a business-critical imbalanced problem, I would not rely solely on accuracy; instead, I would evaluate the model using metrics like Precision, Recall, F1-score, ROC-AUC, and especially the Precision-Recall curve, because they better reflect performance on the minority class.\n","\n"," Finally, I would choose the classification threshold not just at 0.5 but based on business requirements — for example, maximizing Recall to reach more potential responders, or optimizing Precision to avoid wasting campaign resources. This end-to-end process would produce a balanced, well-tuned Logistic Regression model suitable for the marketing campaign’s goals.\n","\n"],"metadata":{"id":"6p9F11ExZbtg"}}]}